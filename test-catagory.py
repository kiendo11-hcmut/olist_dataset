import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from sklearn.preprocessing import LabelEncoder
import numpy as np
import warnings
warnings.filterwarnings('ignore')

from xgboost import XGBRegressor
import matplotlib.pyplot as plt
import seaborn as sns

plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

df = pd.read_csv("data_cleaning0.csv")

# Ki·ªÉm tra t√™n c·ªôt ng√†nh h√†ng (c√≥ th·ªÉ l√† product_category, category_name, etc.)
print("üìã C√°c c·ªôt trong d·ªØ li·ªáu:")
print(df.columns.tolist())

category_col = 'product_category_name'


category_english_col = 'product_category_name_english'


# Target: doanh thu (c√≥ th·ªÉ l√† total_price, revenue, sales, etc.)
target_col = 'total_price'  # Thay ƒë·ªïi n·∫øu c·ªôt doanh thu c√≥ t√™n kh√°c

# ===============================
# 2Ô∏è‚É£ Ph√¢n t√≠ch doanh thu theo ng√†nh h√†ng
# ===============================
print("\n" + "="*70)
print("üìä PH√ÇN T√çCH DOANH THU THEO NG√ÄNH H√ÄNG")
print("="*70)

# Lo·∫°i b·ªè d·ªØ li·ªáu thi·∫øu
df_clean = df[[category_col, target_col]].dropna()

# T·∫°o mapping t√™n ti·∫øng Anh n·∫øu c√≥
if category_english_col and category_english_col in df.columns:
    # T·∫°o dictionary mapping t·ª´ t√™n g·ªëc sang t√™n ti·∫øng Anh
    category_name_map = df[[category_col, category_english_col]].drop_duplicates().set_index(category_col)[category_english_col].to_dict()
else:
    category_name_map = None

# T·ªïng h·ª£p doanh thu theo ng√†nh
category_stats = df_clean.groupby(category_col).agg({
    target_col: ['count', 'sum', 'mean', 'std', 'min', 'max']
}).round(2)

category_stats.columns = ['S·ªë ƒë∆°n', 'T·ªïng doanh thu', 'TB doanh thu', 'ƒê·ªô l·ªách chu·∫©n', 'Min', 'Max']
category_stats = category_stats.sort_values('T·ªïng doanh thu', ascending=False)

print(f"\nüîù Top 10 ng√†nh h√†ng c√≥ doanh thu cao nh·∫•t:")
print(category_stats.head(10).to_string())

# L∆∞u th·ªëng k√™
category_stats.to_csv("revenue_by_category_stats.csv")

# ===============================
# 3Ô∏è‚É£ Chu·∫©n b·ªã features cho m√¥ h√¨nh d·ª± ƒëo√°n
# ===============================
print("\n" + "="*70)
print("üéØ X√ÇY D·ª∞NG M√î H√åNH D·ª∞ ƒêO√ÅN DOANH THU")
print("="*70)

# Ch·ªçn features
features = [
    category_col,
    "order_item_count", 
    "delivery_days", 
    "execution_days",
    "estimated_days", 
    "avg_review_score", 
    "total_freight_value",
    "total_payment", 
    "payment_installments"
]

# Ki·ªÉm tra features c√≥ t·ªìn t·∫°i kh√¥ng
available_features = [f for f in features if f in df.columns]
missing_features = [f for f in features if f not in df.columns]

if missing_features:
    print(f"\n‚ö†Ô∏è  C√°c features kh√¥ng t·ªìn t·∫°i: {missing_features}")
    print(f"‚úÖ S·ª≠ d·ª•ng features: {available_features}")
    features = available_features

# Lo·∫°i b·ªè d·ªØ li·ªáu thi·∫øu
df_model = df[features + [target_col]].dropna()
print(f"\nüìä S·ªë l∆∞·ª£ng d·ªØ li·ªáu sau khi l√†m s·∫°ch: {len(df_model)}")

# Encode category v·ªÅ d·∫°ng s·ªë
le = LabelEncoder()
df_model[category_col + '_encoded'] = le.fit_transform(df_model[category_col])

# L∆∞u mapping ƒë·ªÉ decode sau n√†y
category_mapping = pd.DataFrame({
    'category': le.classes_,
    'encoded_value': range(len(le.classes_))
})
category_mapping.to_csv("category_encoding_mapping.csv", index=False)

# Chu·∫©n b·ªã X, y
numeric_features = [f for f in features if f != category_col]
X = df_model[numeric_features + [category_col + '_encoded']]
y = df_model[target_col]

# Chia train/test theo stratify category
# ===============================
try:
    X_train, X_test, y_train, y_test, cat_train, cat_test = train_test_split(
        X, y, df_model[category_col], 
        test_size=0.2, 
        random_state=42,
        stratify=df_model[category_col]
    )
    print("\n‚úÖ Chia d·ªØ li·ªáu theo stratify category")
except ValueError:
    # N·∫øu c√≥ category c√≥ qu√° √≠t samples
    X_train, X_test, y_train, y_test, cat_train, cat_test = train_test_split(
        X, y, df_model[category_col], 
        test_size=0.2, 
        random_state=42
    )
    print("\n‚ö†Ô∏è M·ªôt s·ªë category c√≥ qu√° √≠t m·∫´u, s·ª≠ d·ª•ng random split")

print(f"Train size: {len(X_train)}, Test size: {len(X_test)}")

# Ki·ªÉm tra ph√¢n ph·ªëi category
print("\n Ph√¢n ph·ªëi ng√†nh h√†ng trong Train vs Test:")
train_dist = cat_train.value_counts(normalize=True).head(10) * 100
test_dist = cat_test.value_counts(normalize=True).head(10) * 100
dist_compare = pd.DataFrame({
    'Train (%)': train_dist,
    'Test (%)': test_dist
}).round(2)
print(dist_compare)

# ===============================
#  Hu·∫•n luy·ªán c√°c m√¥ h√¨nh
# ===============================
models = {}
predictions = {}
results = []

print("\n" + "="*70)
print("üöÄ HU·∫§N LUY·ªÜN M√î H√åNH")
print("="*70)

# Random Forest
print("\n1Ô∏è‚É£  Random Forest...")
rf = RandomForestRegressor(
    n_estimators=200,
    max_depth=15,
    min_samples_split=10,
    min_samples_leaf=4,
    random_state=42,
    n_jobs=-1
)
rf.fit(X_train, y_train)
models['Random Forest'] = rf
predictions['Random Forest'] = rf.predict(X_test)

print("2Ô∏è‚É£  XGBoost...")
xgb = XGBRegressor(
    n_estimators=200,
    max_depth=8,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    n_jobs=-1
)
xgb.fit(X_train, y_train)
models['XGBoost'] = xgb
predictions['XGBoost'] = xgb.predict(X_test)

# ƒê√°nh gi√° m√¥ h√¨nh

print("\n" + "="*70)
print("üìä K·∫æT QU·∫¢ ƒê√ÅNH GI√Å")
print("="*70)

for model_name, y_pred in predictions.items():
    r2 = r2_score(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mape = np.mean(np.abs((y_test.values - y_pred) / y_test.values)) * 100
    
    results.append({
        'Model': model_name,
        'R¬≤': r2,
        'MAE': mae,
        'RMSE': rmse,
        'MAPE (%)': mape
    })
    
    print(f"\n{model_name}:")
    print(f"  R¬≤: {r2:.4f}")
    print(f"  MAE: {mae:.2f}")
    print(f"  RMSE: {rmse:.2f}")
    print(f"  MAPE: {mape:.2f}%")

results_df = pd.DataFrame(results).sort_values('R¬≤', ascending=False)

print("\n" + "="*70)
print(" X·∫æP H·∫†NG M√î H√åNH")
print("="*70)
print(results_df.to_string(index=False))

best_model_name = results_df.iloc[0]['Model']
best_model = models[best_model_name]
best_predictions = predictions[best_model_name]

#  Feature Importance

print("\n" + "="*70)
print(f"üîç FEATURE IMPORTANCE - {best_model_name}")
print("="*70)

feature_names = X.columns.tolist()
importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': best_model.feature_importances_
}).sort_values('Importance', ascending=False)

# Thay t√™n category_encoded v·ªÅ t√™n g·ªëc
importance_df['Feature'] = importance_df['Feature'].str.replace('_encoded', ' (Category)')
print(importance_df.to_string(index=False))

# ===============================
# D·ª± ƒëo√°n theo t·ª´ng ng√†nh h√†ng
# ===============================
print("\n" + "="*70)
print("üéØ D·ª∞ ƒêO√ÅN DOANH THU THEO NG√ÄNH H√ÄNG")
print("="*70)

# T·∫°o DataFrame k·∫øt qu·∫£ test
test_results = X_test.copy()
test_results['actual_revenue'] = y_test.values
test_results['predicted_revenue'] = best_predictions
test_results['error'] = y_test.values - best_predictions
test_results['abs_error'] = abs(test_results['error'])
test_results['category'] = cat_test.values

# T·ªïng h·ª£p theo ng√†nh h√†ng
category_performance = test_results.groupby('category').agg({
    'actual_revenue': ['count', 'sum', 'mean'],
    'predicted_revenue': ['sum', 'mean'],
    'abs_error': 'mean'
}).round(2)

category_performance.columns = ['Sample Count', 'Actual Revenue', 'Actual Avg', 
                                'Predicted Revenue', 'Predicted Avg', 'Avg Error']
category_performance['Accuracy (%)'] = (100 - (category_performance['Avg Error'] / 
                                        category_performance['Actual Avg'] * 100)).round(2)
category_performance = category_performance.sort_values('Actual Revenue', ascending=False)

print("\n D·ª± ƒëo√°n doanh thu theo ng√†nh h√†ng (Top 10):")
print(category_performance.head(10).to_string())

# L∆∞u d·ª± ƒëo√°n theo ng√†nh h√†ng
category_performance.to_csv("revenue_prediction_by_category.csv")

# L∆∞u chi ti·∫øt test set
test_results.to_csv("test_predictions_detail.csv", index=False)

#  T√¨m ng√†nh h√†ng d·ª± ƒëo√°n t·ªët/k√©m
print("\n" + "="*70)
print("------ Top 5 ng√†nh h√†ng d·ª± ƒëo√°n CH√çNH X√ÅC nh·∫•t:")
print("="*70)
best_categories = category_performance.nlargest(5, 'Accuracy (%)')
print(best_categories[['Sample Count', 'Actual Avg', 'Predicted Avg', 'Accuracy (%)']].to_string())

print("\n" + "="*70)
print("------ Top 5 ng√†nh h√†ng d·ª± ƒëo√°n K√âM nh·∫•t:")
print("="*70)
worst_categories = category_performance.nsmallest(5, 'Accuracy (%)')
print(worst_categories[['Sample Count', 'Actual Avg', 'Predicted Avg', 'Accuracy (%)']].to_string())


# L·∫•y Top 15 ng√†nh c√≥ doanh thu cao nh·∫•t ƒë·ªÉ v·∫Ω
top_categories = category_performance.head(10)

# Map t√™n sang ti·∫øng Anh n·∫øu c√≥
if category_name_map:
    top_categories_display = top_categories.copy()
    top_categories_display.index = top_categories_display.index.map(
        lambda x: category_name_map.get(x, x)[:30]  # Gi·ªõi h·∫°n 30 k√Ω t·ª±
    )
    display_names = top_categories_display.index
else:
    display_names = top_categories.index

# 1. Bi·ªÉu ƒë·ªì so s√°nh Doanh thu Th·ª±c t·∫ø vs D·ª± ƒëo√°n (Bar Chart)
fig, axes = plt.subplots(2, 2, figsize=(18, 12))
fig.suptitle(f'Ph√¢n t√≠ch D·ª± ƒëo√°n Doanh thu theo Ng√†nh h√†ng - Model: {best_model_name}', 
             fontsize=16, fontweight='bold')

# Chart 1: Doanh thu trung b√¨nh - Th·ª±c t·∫ø vs D·ª± ƒëo√°n
ax1 = axes[0, 0]
x_pos = np.arange(len(top_categories))
width = 0.35

bars1 = ax1.bar(x_pos - width/2, top_categories['Actual Avg'], width, 
                label='Th·ª±c t·∫ø', alpha=0.8, color='#2E86AB')
bars2 = ax1.bar(x_pos + width/2, top_categories['Predicted Avg'], width,
                label='D·ª± ƒëo√°n', alpha=0.8, color='#A23B72')

ax1.set_xlabel('Ng√†nh h√†ng', fontsize=11, fontweight='bold')
ax1.set_ylabel('Doanh thu trung b√¨nh', fontsize=11, fontweight='bold')
ax1.set_title('So s√°nh Doanh thu TB: Th·ª±c t·∫ø vs D·ª± ƒëo√°n (Top 15)', fontsize=12, fontweight='bold')
ax1.set_xticks(x_pos)
ax1.set_xticklabels(display_names, rotation=45, ha='right', fontsize=9)
ax1.legend()
ax1.grid(axis='y', alpha=0.3)

# Th√™m gi√° tr·ªã l√™n bar
for bars in [bars1, bars2]:
    for bar in bars:
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.0f}', ha='center', va='bottom', fontsize=8)

# Chart 2: T·ªïng doanh thu - Th·ª±c t·∫ø vs D·ª± ƒëo√°n
ax2 = axes[0, 1]
bars3 = ax2.bar(x_pos - width/2, top_categories['Actual Revenue'], width,
                label='Th·ª±c t·∫ø', alpha=0.8, color='#06A77D')
bars4 = ax2.bar(x_pos + width/2, top_categories['Predicted Revenue'], width,
                label='D·ª± ƒëo√°n', alpha=0.8, color='#F18F01')

ax2.set_xlabel('Ng√†nh h√†ng', fontsize=11, fontweight='bold')
ax2.set_ylabel('T·ªïng doanh thu', fontsize=11, fontweight='bold')
ax2.set_title('So s√°nh T·ªïng doanh thu: Th·ª±c t·∫ø vs D·ª± ƒëo√°n (Top 15)', fontsize=12, fontweight='bold')
ax2.set_xticks(x_pos)
ax2.set_xticklabels(display_names, rotation=45, ha='right', fontsize=9)
ax2.legend()
ax2.grid(axis='y', alpha=0.3)


# Chart 4: ƒê·ªô ch√≠nh x√°c theo ng√†nh
ax3 = axes[1, 1]
colors_accuracy = ['#06A77D' if x >= 90 else '#F18F01' if x >= 80 else '#D62828' 
                   for x in top_categories['Accuracy (%)']]
bars5 = ax3.barh(range(len(top_categories)), top_categories['Accuracy (%)'], 
                 color=colors_accuracy, alpha=0.8)

ax3.set_yticks(range(len(top_categories)))
ax3.set_yticklabels(display_names, fontsize=9)
ax3.set_xlabel('ƒê·ªô ch√≠nh x√°c (%)', fontsize=11, fontweight='bold')
ax3.set_title('ƒê·ªô ch√≠nh x√°c d·ª± ƒëo√°n theo Ng√†nh h√†ng (Top 15)', 
              fontsize=12, fontweight='bold')
ax3.grid(axis='x', alpha=0.3)
ax3.axvline(x=90, color='green', linestyle='--', alpha=0.5, label='M·ª•c ti√™u: 90%')
ax3.legend()

# Th√™m gi√° tr·ªã
for i, (bar, val) in enumerate(zip(bars5, top_categories['Accuracy (%)'])):
    ax3.text(val + 1, i, f'{val:.1f}%', va='center', fontsize=8)

plt.tight_layout()
plt.show()

# 2. Bi·ªÉu ƒë·ªì chi ti·∫øt sai s·ªë theo ng√†nh
fig2, axes2 = plt.subplots(1, 2, figsize=(16, 6))
fig2.suptitle('Ph√¢n t√≠ch Sai s·ªë D·ª± ƒëo√°n theo Ng√†nh h√†ng', fontsize=16, fontweight='bold')

# Chart 5: Sai s·ªë tuy·ªát ƒë·ªëi trung b√¨nh
ax5 = axes2[0]
top_error = category_performance.nlargest(15, 'Avg Error')

# Map t√™n ti·∫øng Anh
if category_name_map:
    top_error_display = top_error.copy()
    top_error_display.index = top_error_display.index.map(
        lambda x: category_name_map.get(x, x)[:30]
    )
    display_names_error = top_error_display.index
else:
    display_names_error = top_error.index

colors_error = plt.cm.Reds(np.linspace(0.4, 0.9, len(top_error)))
bars6 = ax5.barh(range(len(top_error)), top_error['Avg Error'], color=colors_error, alpha=0.8)

ax5.set_yticks(range(len(top_error)))
ax5.set_yticklabels(display_names_error, fontsize=9)
ax5.set_xlabel('Sai s·ªë tuy·ªát ƒë·ªëi TB', fontsize=11, fontweight='bold')
ax5.set_title('Top 15 Ng√†nh c√≥ Sai s·ªë L·ªõn nh·∫•t', fontsize=12, fontweight='bold')
ax5.grid(axis='x', alpha=0.3)

for i, (bar, val) in enumerate(zip(bars6, top_error['Avg Error'])):
    ax5.text(val + val*0.02, i, f'{val:.0f}', va='center', fontsize=8)

# Chart 6: % Sai s·ªë so v·ªõi doanh thu th·ª±c
ax6 = axes2[1]
top_categories_err = category_performance.head(15).copy()

# Map t√™n ti·∫øng Anh
if category_name_map:
    display_names_pct = [category_name_map.get(x, x)[:30] for x in top_categories_err.index]
else:
    display_names_pct = top_categories_err.index

error_pct = (top_categories_err['Avg Error'] / top_categories_err['Actual Avg'] * 100)
colors_pct = ['#06A77D' if x <= 10 else '#F18F01' if x <= 20 else '#D62828' for x in error_pct]
bars7 = ax6.bar(range(len(top_categories_err)), error_pct, color=colors_pct, alpha=0.8)

ax6.set_xticks(range(len(top_categories_err)))
ax6.set_xticklabels(display_names_pct, rotation=45, ha='right', fontsize=9)
ax6.set_ylabel('% Sai s·ªë', fontsize=11, fontweight='bold')
ax6.set_title('% Sai s·ªë so v·ªõi Doanh thu th·ª±c (Top 15)', fontsize=12, fontweight='bold')
ax6.grid(axis='y', alpha=0.3)
ax6.axhline(y=10, color='green', linestyle='--', alpha=0.5, label='M·ª•c ti√™u: ‚â§10%')
ax6.axhline(y=20, color='orange', linestyle='--', alpha=0.5, label='Ch·∫•p nh·∫≠n: ‚â§20%')
ax6.legend()

for bar, val in zip(bars7, error_pct):
    ax6.text(bar.get_x() + bar.get_width()/2., val + 0.5,
            f'{val:.1f}%', ha='center', va='bottom', fontsize=8)

plt.tight_layout()
plt.show()

